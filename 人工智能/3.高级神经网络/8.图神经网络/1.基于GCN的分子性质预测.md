# 基于GCN的分子性质预测

学习了图数据天然适合描述分子的二维结构数据，本文将使用ZNIC数据集实现一个分子性质预测模型，以下是代码详解。

## 项目目录

本项目的目录结构如下：

```
GCN Molecular Property/
├── data/
│   ├── delaney-processed.csv
│   └── ZINC.csv
├── result/
│   ├── gcn_model.pth
│   └── losses.csv
├── ChemGraph.py
├── config.py
├── dataset.py
├── GCNModel.py
├── preodect.py
└── train.py
```

## 超参数配置

这里主要设置了数据集文件路径和模型权重保存路径，批次大小、训练轮数、学习率等。其中最主要的是节点向量维度`N_DIM`，该值必须和graph中的节点向量维度一致，在不同的学习任务中可能会选择不同的原子节点属性，这会造成节点维度的变化，需要特别注意输入参数的一致性。

以下代码在`config.py`中实现：
```python
import torch
import torch.nn as nn

# 设备
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# 数据集路径
DELANEY_FILE = "./data/delaney-processed.csv"
# 权重保存文件
PT_PATH = "./result/gcn_model.pth"
# 损失保存路径
LOSS_PATH = "./result/losses.csv"

# 节点特征向量维度
N_DIM = 22
# 批次大小
BATCH_SIZE = 32
# 训练轮数
EPOCH = 200
# 学习率
LR = 5e-3
```

## 加载数据集

以下代码在`dataset.py`中实现：
```python
import pandas as pd
from rdkit import Chem
import torch
from torch.utils.data import Subset
from torch_geometric.loader import DataLoader
from torch_geometric.data import Dataset
from ChemGraph import mol_to_graph
from config import *

# 选择要学习预测的指标
TASK = 'logP'
# 读取数据集csv文件
df = pd.read_csv(DELANEY_FILE)
# 将smiles转为rdkit的mol对象
df["mol"] = df["SMILES"].apply(lambda x: Chem.MolFromSmiles(x))
# 去除转化失败的空值
df = df[df["mol"].notna()]
# 选择属性构造新列表
df = df[["ZINC ID", "SMILES", TASK,"mol"]]

# 数据类，继承Dataset
class MolGraphDataset(Dataset):
    # 初始化方法需传入列表、mol对象列名、选择的属性、转换函数
    def __init__(self, 
    df, 
    mol_col="mol", 
    target_col=TASK, 
    transform_fn=None
    ):
        super().__init__()
        self.df = df
        self.mol_col = mol_col
        self.target_col = target_col
        self.transform_fn = transform_fn
    # len方法
    def len(self):
        return len(self.df)
    # get方法
    def get(self, idx):
        row = self.df.iloc[idx]
        mol = row[self.mol_col]

        try:
            G = self.transform_fn(mol)
            if self.target_col is not None:
                target = torch.tensor([row[self.target_col]], dtype=torch.float)
                G.y = target
            return G
        except:
            return None

# 初始化完整的分子图数据集
full_dataset = MolGraphDataset(
    df=df,
    mol_col="mol",
    target_col=TASK,
    transform_fn=mol_to_graph
)
data_size = len(full_dataset)

# 划分比例
test_ratio = 0.10
# 测试集大小
test_size = int(data_size * test_ratio)
# 训练集大小
train_size = data_size - test_size

# 生成随机打乱的索引
random_seed = 42
torch.manual_seed(random_seed)
indices = torch.randperm(data_size)

# 分割为训练集和测试集索引
train_indices = indices[:train_size]
test_indices = indices[train_size:]

# 用Subset构建训练集和测试集
train_dataset = Subset(full_dataset, train_indices)
test_dataset = Subset(full_dataset, test_indices)

# 构建数据加载器
train_loader = DataLoader(
    train_dataset,
    batch_size=BATCH_SIZE,
    shuffle=True,       # 训练集打乱
    drop_last=False,    # 不丢弃最后一个不足批次的数据
    num_workers=0       # 多进程加载
)
test_loader = DataLoader(
    test_dataset,
    batch_size=BATCH_SIZE,
    shuffle=False,      # 测试集不打乱
    drop_last=False,
    num_workers=0
)
```

测试模块
```python
if __name__ == '__main__':
    print(f"Number of molecules in the dataset: {df.shape[0]}")
    print(df.head())
    print(f"完整数据集大小: {data_size}")
    print(f"训练集大小: {len(train_dataset)}, 测试集大小: {len(test_dataset)}")
    print("验证训练集批次：")
    for batch in train_loader:
        print(f"节点特征形状: {batch.x.shape}")
        print(f"标签形状: {batch.y.shape}")
        print(f"边索引形状: {batch.edge_index.shape}")
        print(f"边属性形状: {batch.edge_attr.shape}")
        break
```

## 模型定义

以下代码在`GCNModel.py`中实现：
```python
import torch.nn as nn
from torch_geometric.nn.conv import GCNConv
from torch_geometric.nn.pool import global_mean_pool

class GCNModel(nn.Module):
    def __init__(self, ndim, hidden_dims):
        super(GCNModel, self).__init__()
        dims = [ndim] + hidden_dims
        net = []

        # 归一化层
        self.bn = nn.BatchNorm1d(dims[0])

        # (22→128) (128→64) (64→32)
        for i in range(len(dims)-1):
            net.extend([
                GCNConv(dims[i], dims[i+1], add_self_loops=True),
                nn.ReLU(),
            ])
        self.net = nn.Sequential(*net)

        # 线性层
        self.fc = nn.Linear(dims[-1], 1)


    def forward(self, data):
        # 节点归属标签 [total_nodes]
        batch = data.batch
        # 节点特征 [total_nodes, ndim]
        out = data.x

        # 输入批次归一化层
        out = self.bn(out)
        # 边索引 [2, total_edges]
        edge_index = data.edge_index.long()

        # 逐层执行GCN
        # 最终的out [total_nodes, 32]
        for idx in range(len(self.net)//2):
            # 图卷积层
            out = self.net[2*idx](out, edge_index)
            # ReLU激活
            out = self.net[2*idx+1](out)

        
        # 固定池化层（每个分子的所有节点特征求平均）
        # out [batch_size, 32]
        out = global_mean_pool(out, batch)
        # 输出预测值 [batch_size, 1]
        out = self.fc(out)
        return out
```

测试模块
```python
if __name__ == '__main__':
    from config import *
    model = GCNModel(ndim=N_DIM, hidden_dims=[128, 64, 32])
    model = model.to(DEVICE)
    model = model.float()
    optimizer = torch.optim.Adam(model.parameters(), lr=LR)
    criterion = nn.MSELoss()
    print("Number of trainable parameters:",
        sum(p.numel() for p in model.parameters() if p.requires_grad))
    print(model)
```

## 训练模型

以下代码在`train.py`中实现：
```python
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
import torch
import torch.nn as nn

from dataset import *
from ChemGraph import *
from GCNModel import *
from config import *

# 训练周期
def train_epoch(model, criterion, optimizer, dataloader):
    losses = []
    model.train()
    for G in dataloader:
        G.to(DEVICE)
        y_true = G.y
        optimizer.zero_grad()
        y_pred = model(G)
        loss = criterion(y_pred, y_true.reshape(y_pred.shape))
        loss.backward()
        optimizer.step()
        losses.append(loss.cpu().detach().item())
    return losses

# 测试周期
def val_epoch(model, criterion, dataloader):
    losses = []
    model.eval()
    with torch.no_grad():
        for G in dataloader:
            G = G.to(DEVICE)
            y_true = G.y
            y_pred = model(G)
            loss = criterion(y_pred, y_true.reshape(y_pred.shape))
            losses.append(loss.cpu().detach().item())
    return losses
```
正式训练
```python
if __name__ == '__main__':
    # 模型初始化
    model = GCNModel(ndim=N_DIM, hidden_dims=[128, 64, 32])
    # 迁移设备
    model.to(DEVICE)
    # 确保模型参数为float类型
    model = model.float()
    # 优化器
    optimizer = torch.optim.Adam(model.parameters(), lr=LR)
    # 均方差损失函数
    criterion = nn.MSELoss()
    # 训练误差
    train_loss = []
    # 评估误差
    val_loss = []
    # 初始化进度条
    loss_dict = {"avg_train_loss":0,"avg_val_loss":0}
    pbar = tqdm(
        range(1, EPOCH+1), 
        desc="Epoch", 
        leave=True, 
        postfix=loss_dict,
        dynamic_ncols=True
    )
    # 训练循环
    for epoch in pbar:
        # 训练并更新权重
        losses = train_epoch(model, criterion, optimizer, train_loader)
        avg_train_loss = np.mean(losses)
        train_loss.append(avg_train_loss)
        # 评估
        losses = val_epoch(model, criterion, test_loader)
        avg_val_loss = np.mean(losses)
        val_loss.append(avg_val_loss)
        # 更新进度条参数
        loss_dict["avg_train_loss"] = avg_train_loss
        loss_dict["avg_val_loss"] = avg_val_loss
        pbar.set_postfix(loss_dict)
    # 保存模型
    torch.save(model.state_dict(), PT_PATH)
    print("\n训练完成！模型权重已保存为:", PT_PATH)

    # 展示损失函数
    f, ax = plt.subplots(1, 1, figsize=(5,5))
    ax.plot(train_loss, c="blue", label="Training")
    ax.plot(val_loss, c="red", label="Test")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.legend()
    plt.show()
    
    # 保存每轮损失
    import pandas as pd
    df = pd.DataFrame({
        'Epoch': range(1, len(train_loss) + 1),
        'Training Loss': train_loss,
        'Test Loss': val_loss
    })
    df.to_csv(LOSS_PATH, index=False)
```

## 预测模型