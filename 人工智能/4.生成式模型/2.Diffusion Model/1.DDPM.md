# DDPM

上文我们介绍了扩散模型的核心思想，而DDPM作为首个将扩散模型具体实现的模型，自2020年论文发表以来就受到广泛应用，本文将对DDPM的原理和实现做具体说明。

## 前向加噪

模型训练时需要输入给定原始图像加噪后的数据，设原数据为$x_0$，第t步加噪后的数据为$x_t$，最终加噪完成的数据$x_T$应为纯噪声数据。

我们假设随机噪声符合正态分布，即$\varepsilon_t = \mathcal{N}(0,1)$，加噪过程可以描述为均值为$\sqrt{1-\beta_t}x_{t-1}$，方差为$\beta_tI$的正态分布，$I$ 代表单位矩阵：
$$q(x_t|x_{t-1}) = \mathcal{N}(x_t;\sqrt{1-\beta_t}x_{t-1},\beta_tI)$$

由此可以得到加噪迭代公式：

$$
x_t = \sqrt{\alpha_t}x_{t-1} + \sqrt{\beta_t}\varepsilon_t; \quad \alpha_t = 1- \beta_t
$$


迭代后推导出的加噪公式，即第t步加噪后的数据可表示为：
$$ x_t = \sqrt{\bar{\alpha}_t}\cdot x_0 + \sqrt{1-\bar{\alpha}_t} \cdot \varepsilon , \quad \bar{\alpha}_t = \prod_T \alpha_t$$
写成加噪分布的形式为：
$$
q(x_{t}|x_0) =\mathcal{N}(x_{t};\sqrt{\bar{\alpha}_t}x_0,(1-\bar{\alpha}_t)I)
$$

## 反向去噪

Diffusion Model并不是直接由$x_t$预测$x_{t-1}$，而是预测加在$x_t$上的“噪声”，通过去噪得到$x_{t-1}$，这样做是兼顾 “训练效率、模型稳定性、生成多样性” 的最优选择。

反向过程则是从纯噪声$x_T$ 到真实数据 $x_0$，这里反向分布公式可由**贝叶斯定理**推出：
$$q(x_{t-1} | x_t) = \frac{q(x_t|x_{t-1}) \cdot q(x_{t-1}|x_0)}{q(x_t|x_0)}$$

该公式表示给定$x_t$去求$x_{t-1}$，分子分母的三个分布在前向加噪中都已得到，分式的三个分布都是高斯分布，则$q(x_{t-1} | x_t)$也必然是高斯分布。

- 单步加噪分布，$\alpha_t=1-\beta_t$，$\beta_t$是单步噪声方差：
  $$q(x_t|x_{t-1}) \thicksim \mathcal{N}(\sqrt{\alpha_t}x_{t-1},(1-\alpha_t)I)$$

- 从$x_0$到$x_{t-1}$的累计加噪分布，$\bar{\alpha}_{t-1} = \prod\nolimits_{i=1}^{t-1} \alpha_i$
  $$q(x_{t-1}|x_0) \thicksim \mathcal{N}( \sqrt{\bar{\alpha}_{t-1}}x_0,(1-\bar{\alpha}_{t-1})I )$$

- 从$x_0$到$x_t$的累计加噪分布，$\bar{\alpha}_t = \prod\nolimits_{i=1}^t \alpha_i$
  $$q(x_t|x_0) \thicksim \mathcal{N} ( \sqrt{\bar{\alpha}_t}x_0,(1-\bar{\alpha}_t)I )$$


随后推导出已知第t步时第t-1步的数据分布$q(x_{t-1}|x_t)$的均值和方差，用角标表示条件分布。
均值：
$$ \mu_{t-1|t} = \frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}x_t + \frac{\sqrt{\bar{\alpha}_{t-1}}(1-\alpha_t)}{1-\bar{\alpha}_t} x_0 $$
方差：
$$ \sigma_{t-1|t} = \frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_t}(1-\alpha_t)I$$

这里的均值使用了参数$x_0$，但在预测中我们并不预先知道，不然就不用预测了，所以我们要用$x_t$来预测$x_0$，由前向扩散公式反解出$x_0$，这里$\varepsilon_t$是第t步的真实噪声：
$$x_0 = \frac{1}{\sqrt{\bar{\alpha}_t}} (x_t - \sqrt{1-\bar{\alpha}_t} \cdot \varepsilon_t) $$

将其代入反向分布的均值$\mu_{t-1|t}$中，用预测噪声$\varepsilon_ \theta$近似真实噪声$\varepsilon_t$，得到反向去噪公式：
$$ x_{t-1} = \frac{1}{\sqrt{\alpha_t}} (x_t - \frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}} \cdot \varepsilon_ \theta(x_t,t)) + \sigma_t \cdot z $$


这里$\sigma_t = \sqrt{\frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_t}(1-\alpha_t)}$是噪声强度系数，$z \thicksim \mathcal{N}(0,1)$是随机噪声。
因此，利用该公式，针对模型每轮预测的噪声$\varepsilon_ \theta$，都可以得到下一步的数据$x_{t-1}$


## 损失函数



## 模型训练流程

DDPM的单步训练示意图如下：

![](1.1.svg)

图中，我们先把预测网路部分抽形为一个黑盒模型，它接收时间步$t$和含噪数据$x_t$，预测出加在数据中的噪声$\varepsilon$，再通过反向过程去除噪声得到下一步的数据$x_{t-1}$


## 预测网络

接下来我们讨论Diffusion Model预测噪声功能的核心部分，根据上述讨论，我们可以理解，扩散模型实际上还是一种神经网络，只不过该神经网络的输入数据经过处理，接收含噪数据和时间步，输出的预测数据也经过了处理得到去噪后数据，那么接下来我们深入研究核心模块——Unet网络。

对于它的具体框架我们在前文已做讨论，在此不做展开。

## 时间步嵌入

根据扩散模型的原理我们知道，在预测网络训练时需要输入当前的时间T，所谓时间步嵌入就是将标量T通过给定的数学公式转换为一个时间向量，再通过线性变换与图像数据输入融合。

### 时序向量生成

通常，我们会选择基于正弦和余弦函数的位置编码来做时间步嵌入，其具体公式如下：

$$
\begin{align*}
& PE(t,2i) = sin(\frac{t}{10000^k}) \\
& PE(t,2i+1) = cos(\frac{t}{10000^k}) \\
& k=\frac{2i}{d_{model}}
\end{align*}
$$

公式$PE(t,x)$表示时间步 $t$ 对应的嵌入向量的第$x$个元素，$x$的取值范围是$[0, d_{model}-1]$。对于向量的偶数位元素使用$sin$计算，奇数位使用$cos$计算。

**示例**

我们想计算一个十一维嵌入向量第$t=4$时刻第$5$个元素的值，因为$5$是奇数，所以使用$cos$公式计算，且$i=\frac{(5-1)}{2}=2$，代入：

$$
\begin{align*}
k=&\frac{2 \times 2}{11} = \frac{4}{11} \\
PE(4,5)=&cos(\frac{4}{10000^{(4/11)}}) \approx 0.99015
\end{align*}
$$


对于一个维度是11的嵌入向量，我们可以计算出$t_0 \sim t_9$每个时间步对应的向量：

```
t_0:[0,	1,	0,	1,	0,	1,	0,	1,	0,	1,	0]
t_1:[0.841470985,	0.540302306,	0.18628711,	0.98249535,	0.035104703,	0.99938364,	0.006579285,	0.999978356,	0.001232846,	0.99999924,	0.000231013]
t_2:[0.909297427,	-0.416146837,	0.366052439,	0.930594225,	0.070166132,	0.99753532,	0.013158285,	0.999913426,	0.002465691,	0.99999696,	0.000462026]
t_3:[0.141120008,	-0.989992497,	0.533002529,	0.846113647,	0.105141066,	0.994457317,	0.019736715,	0.999805212,	0.003698532,	0.99999316,	0.000693039]
t_4:[-0.756802495,	-0.653643621,	0.681292572,	0.732011223,	0.13998639,	0.990153428,	0.026314291,	0.999653719,	0.004931367,	0.999987841,	0.000924052]
t_5:[-0.958924275,	0.283662185,	0.80573104,	0.592281598,	0.17465915,	0.984628956,	0.032890728,	0.999458954,	0.006164195,	0.999981001,	0.001155065]
t_6:[-0.279415498,	0.960170287,	0.901961427,	0.431816609,	0.209116605,	0.977890713,	0.039465741,	0.999220924,	0.007397013,	0.999972642,	0.001386077]
t_7:[0.656986599,	0.753902254,	0.966614776,	0.256234022,	0.243316277,	0.969947003,	0.046039046,	0.998939641,	0.00862982,	0.999962762,	0.00161709]
t_8:[0.989358247,	-0.145500034,	0.997427618,	0.071680862,	0.277216008,	0.960807621,	0.052610358,	0.998615116,	0.009862614,	0.999951363,	0.001848103]
t_9:[0.412118485,	-0.911130262,	0.993321218,	-0.115381796,	0.310774009,	0.950483832,	0.059179393,	0.998247364,	0.011095393,	0.999938444,	0.002079115]
```
通过绘图查看0~50时间步下嵌入向量前7个元素的分布，观察$t、i$两个变量对数值的影响。

![](嵌入向量.svg)

### 向量嵌入

在得到$t_i$时刻的$n$维嵌入向量后，往往需要将其与图像数据嵌入，在扩散模型中，主要通过特征融合的方式注入到 `UNet` 网络。